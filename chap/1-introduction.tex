\chapter{Introduction}
\label{cha:Introduction}

Model selection problems arise in various scientific research areas. It is
actually about making decisions about which model we should use to describe
the data observed. Therefore, we insist a decision-oriented perspective of the
model selection problem. Two kinds of approaches to model selection are
discussed in this report. The first is the information-theoretic approach and
the second is the Bayesian approach. The decision-oriented perspective is
applicable to both cases as we will see in the rest of this report. It shall
be noted that the two approaches are closely related. For example a modest
amount of literal on the choice of priors in Bayesian statistics used results
from the information theory. And some information approaches have a Bayesian
interpretation.

In our own work, Bayesian model comparison, selection and averaging were
applied to a class of model called compartmental models. The results were
compared with classical model selection using (corrected) Akaike's information
criterion (\aicc). Our work is attached at the end this report. It was shown
that Bayesian modeling had significant improvement over classical information
criteria based model selection. However, there were also many difficulties and
limitations encountered in this work.

The literature review in this report serves two purpose. First, the methods we
used and those compared or contrast to, are reviewed and justified in this
report. We aim to answer questions like ``why the \aic based methods would not
work for this kind of complex models'' or ``why we need Bayesian modeling for
these models''. The second purpose is to review the computation difficulties
and limitations we met in the current work and therefore motivated our future
research on new computation techniques for Bayesian modeling.

Chapter~\ref{cha:Information-theoretic model selection} review the
information-theoretic model selection methods. They are still widely used in
many areas due to their simplicity in computation. However the limitations are
clearly demonstrated in our work and justified in this report.
Chapter~\ref{cha:Bayesian model selection} review the basic methodology of
Bayesian model comparison and selection. Chapter~\ref{cha:Bayesian computation
  with Monte Carlo methods} review Monte Carlo methods for Bayesian
computation. It will be shown that the current methods either suffers from
difficulties of implementation or unsatisfied inference results. We are
therefore motivated to seek new methods that satisfy the following criteria.
First it should be applicable to a wide range of models, with either high
dimensions or complex model specifications. Second it should be easier to
implement while give comparable results compared to some currently advanced
methods.

\section{A word on ``true model''}
\label{sec:A word on true model}

The problem of the existence of a ``true model'' as the data generating
mechanism is often questionable. Even it exists, the applicability of model
selection techniques is often challenged by the fact that the ``true model''
is not one of the candidate models at all.

There are two folds of this problem. First, if the ``true model'' exist, and
is not one of the candidate models, is model selection still meaningful? We
believe that, strictly speaking, for real problem, there is no
\emph{parametric} model that can describe the data completely. In this sense,
the ``true model'' is never in the space of model parameterization, except for
the trivial case: for finite data $\bfx = (x_1,\dots,x_n)^T$ and a model $(X_1
= x_1,\dots,X_n = x_n)^T$. However, more than often, some parametric models
serves the purpose as an approximation to the underlying mechanism of the data
generating process well. And model selection techniques provide opportunity to
identify the best approximation among them.

Second, it is often encountered in reality that, all the candidate models are
far from the ``truth''. In this case, the effects of misspecification need to
be assessed. Some techniques were argued to be more robust to these scenarios.
However, there is no simple way to assess this problem. Instead, these effects
often need to be considered on a per problem basis. In this report, the focus
is on the implementation of model selection techniques. However, whenever they
are applied to the real problems, the applicability of them should be
considered carefully.
