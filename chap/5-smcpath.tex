\chapter{New method for Bayesian computation: using sequential Monte Carlo and
  Path sampling}
\label{cha:New method for Bayesian computation}

As already introduced through chapter~\ref{cha:Bayesian model selection}, the
main interest is to estimate the Bayesian factor. In more general setting, it
is the same as estimating the ratio of normalizing constants. In this chapter,
we propose a new method for the estimation, namely using sequential Monte
Carlo techniques and path sampling identity.

The sequential Monte Carlo (\smc) technique constructs an importance
distribution for a target distribution of interest iteratively. The basic idea
is that starting from a distribution which is easy to sample from or
approximated by an importance distribution, and iteratively, move the
importance distribution towards the target distribution of interest. The
distributions constructed by the intermediate steps can be used to estimate
the ratio of normalizing constants between the target and initial
distribution. \parencite{DelMoral2006}

The path sampling technique constructs a continuous \emph{path} to bridge two
distributions, and estimates the logarithm ratio of normalizing constants
between the distributions by an simple identity introduced in
Section~\ref{sec:Path sampling estimator}. The exact meaning of ``path'' will
be introduced in the same section. However, it is worth mention here that,
when implementing the path sampling estimator, this path is often constructed
as a sequence of distributions. \parencite{Gelman1998}

These two techniques can be combined together for the estimating of ratios of
normalizing constants. One way to think of it is that, the path sampling
estimator is one of the ways to use the output from a \smc algorithm to
estimate the (logarithm) ratio of normalizing constants. The other way to
think of it is that, the \smc algorithm provides a simple way to construct a
sequence of distributions to approximate the path required by path sampling
estimator. 

In Section~\ref{sec:smc algorithm}, the \smc algorithm is introduced. In the
section follows, \ref{sec:Path sampling estimator}, the path sampling identity
is presented. In the section follows, a simple example is provided to
illustrate the idea.

\section{\smc algorithm}
\label{sec:smc algorithm}

In this section, the \smc algorithm is introduced. Consider a sequence of
distributions indexed by discrete time $n$, say $\pi_n$. Usually the
distributions are known up to a normalizing constant, say $Z_n$, and $\pi_n
= \gamma_n/Z_n$. The \smc algorithm is based on the sequential importance
sampling techniques. At time $n = 1$, we start with $\pi_1$ and construct an
efficient importance distribution, say $\eta_1$, and we sample $N$ random
numbers from distribution $\eta_1$, called particles. At time $n > 1$,
suppose we have $N$ particles following distribution $\eta_{n-1}$, and we
move these particles in a sensible way to a new distribution $\eta_n$ such
that $\eta_n$ is an efficient importance distribution for $\pi_n$. This is
done by moving the $N$ particles by a sensible Markov kernel $K_n$ such that
particles are moved into high density region of $\pi_n$, and resampling when
the degeneracy of the particles becomes large.

It should be intuitively clear that, in general to do any kind of
estimations, we need be able to compute the importance weights at each time
$n$, and thus $\eta_n$ need to be evaluated point-wise. Typically this is
impossible as 
\begin{equation}
  \eta_n(x_n) = \int\eta_1(x_1)\prod_{j=2}^nK_j(x_{j-1},x_j) \dd x_{1:n-1}
\end{equation}
The \smc algorithm introduce an auxiliary backward Markov chain kernel to
solve this problem for the case where all $E_n$ has the same dimension. The
purpose of the backward kernel is that by construction, the target
distributions increase in dimension while they admit $\pi_n$'s as their
marginal distributions.

In the presentations below, it will be made clear that, the computation of
importance weights is made possible by introducing this auxiliary backward
kernel. At each time $n$, let $L_{n-1}(x_n,x_{n-1})$ be a Markov kernel. It
is called backward in the sense that it is a transition kernel from $x_n$ to
$x_{n-1}$, which is backward in time. And construct,
\begin{equation}
  \tilde{\pi}_n(x_{1:n}) = \frac{\tilde{\gamma}_n(x_{1:n})}{Z_n}
\end{equation}
where $x_{1:n} = (x_1,\dots,x_n)^T$, $Z_n$ is the normalizing constants of
both $\gamma_n$ and $\tilde{\gamma}_n$, and
\begin{equation}
  \tilde{\gamma}_n(x_{1:n}) = \gamma_n(x_n)
  \prod_{k=1}^{n-1}L_k(x_{k+1},x_k).
\end{equation}
By construction, the new target distribution $\tilde{\pi}_n$ satisfies the
requirement for standard sequential importance sampling, and admit $\pi_n$
as its marginal distribution. Therefore any estimates about $\pi_n$ can be
done through sampling from $\tilde{\pi}_n$.

Now back to the standard sequential importance sampling scheme, at time
$n=1$, we have $\eta_1$ as an importance distribution for $\tilde{\pi}_1 =
\pi_1$. Also $N$ particles are sampled, say, $\{X_1^{(i)}\}$. And a set of
corresponding weights $\{W_1^{(i)}\}$ are calculated by,
\begin{align}
  w_1^{(i)} =
  w_1(X_1^{(i)}) &= \frac{\gamma_1(X_1^{(i)})}{\eta_1(X_1^{(i)})}
  \label{eq:ini_weight}\\
  W_1^{(i)} =
  W_1(X_1^{(i)}) &= \frac{w_1(X_1^{(i)})}{\sum_{j=1}^Nw_1(X_1^{(j)})}
  \label{eq:ini_weight_norm}
\end{align}
At time $n-1$, we have a set of weights and particles, $\{W_{n-1}^{(i)},
  X_{n-1}^{(i)}\}$, and move the particles by Markov kernel $K_n(x_{n-1},
x_n)$. Then the new weight for particle $x_{1:n}$ will be,
\begin{align}
  w_n(x_{1:n}) &= \frac{\tilde{\gamma}_n(x_{1:n})}{\eta_n(x_{1:n})}
  \allowdisplaybreaks\notag\\
  &= \frac{\gamma_n(x_n)\prod_{k=1}^{n-1}L_k(x_{k+1},x_k)}
  {\eta_{n-1}(x_{1:n-1})K_n(x_{n-1},x_n)}
  \frac{\gamma_{n-1}(x_{n-1})}{\gamma_{n-1}(x_{n-1})} \notag\\
  &= \frac{\gamma_n(x_n)L_{n-1}(x_n,x_{n-1})\tilde{\gamma}_{n-1}(x_{n-1})}
  {\gamma_{n-1}(x_{n-1})\eta_{n-1}(x_{1:n-1})K_n(x_{n-1},x_n)} \notag\\
  &= w_{n-1}(x_{1:n-1})\tilde{w}_n(x_{n-1},x_n),
\end{align}
where,
\begin{equation}
  \tilde{w}_n(x_{n-1},x_n) =
  \frac{\gamma_n(x_n)L_{n-1}(x_n,x_{n-1})}
  {\gamma_{n-1}(x_{n-1})K_n(x_{n-1},x_n)}.
  \label{eq:incr_weight}
\end{equation}
Applying the above equation for particles $\{W_{n-1}^{(i)}, X_{n-1}^{(i)}\}$
and newly generated $\{X_n^{(i)}\}$, the incremental weights ($\tilde{w}$)
and normalized weights $\{W_n^{(i)}\}$ can therefore be calculated.

\paragraph{Degeneracy} The degeneracy problem mentioned earlier can be
measured by the variance of the normalized weights, as similar in the case
of regular importance sampling. Intuitively, as the time index $n$
increases, the discrepancy between $\eta_n$ and $\tilde{\pi}_n$ increases as
well, and the variance of the normalized important weights tends to
increase.

One way to solve this problem is to resample the particles. The resampling
process consists of selecting new particles and weights such that the
discrepancy is reduced. The resampled particles should also be as good an
approximation to the distribution $\pi_n$ as possible \parencite{Douc2005}.
There are a number of resampling schemes. One class of them is under the
constrains that, each particle $\{X_n^{(i)}\}$ is copied $N_n^{(i)}$ times,
such that $\sum_{i=1}^N N_n^{(i)} = N$, $\Exp[N_n^{(i)}|X_{1:n}] =
NW_n^{(i)}$ and the new particle set has equal weights
\parencite{Douc2005,DelMoral2006}.

To decide when to perform resampling, one can define \ess as
$(\sum_{i=1}^N(W_n^{(i)})^2)^{-1}$, and it can be used as a criterion for
whether or not resampling is required at time $n$.  \parencite{Liu1998}

\paragraph{Summary of the algorithm} In short the algorithm for a sequence
$\pi_n$, $n = 1,\dots,p$, can be represented as below,
\parencite{DelMoral2006}
\begin{enumerate}
  \item Set $n=1$, draw $X_1^{(i)}$ from $\eta_1$ for $i = 1,\dots,N$.  And
    evaluate $\{W_1^{(i)}\}$ by Equations~\eqref{eq:ini_weight}
    and~\eqref{eq:ini_weight_norm}.
  \item If $\ESS < T$, where $T$ is a predefined threshold, resample.
  \item Set $n = n + 1$, if $n = p + 1$, stop and exit the algorithm.
    Otherwise, draw $X_n^{(i)}$ from $K_n(X_{n-1}^{(i)},\cdot)$, and compute
    $\{\tilde{w}_n(X_{n-1}^{(i)},
      X_n^{(i)}\}$ by Equation~\eqref{eq:incr_weight}. The new normalized
    weights, $\{W_n^{(i)}\}$ is computed by
    \begin{equation}
      W_n^{(i)} = \frac{W_{n-1}^{(i)}\tilde{w}_n(X_{n-1}^{(i)},X_n^{(i)})}
      {\sum_{j=1}^NW_{n-1}^{(j)}\tilde{w}_n(X_{n-1}^{(j)},X_n^{(j)})}
    \end{equation}
  \item Go to step 3.
\end{enumerate}

A few problems remains here to actually implement the algorithm. First is
the choice of the kernel $K_n$.  The second problem is the optimization of
the backward kernel $L_{n-1}$.

\subsection{Choice of forward kernels}
\label{sub:Choice of forward kernels}

In general, the \smc algorithm construct $N$ inhomogeneous Markov chains
$\{X_{1:n}^{(i)}\}$. In most cases the marginal distributions for $X_{1:n}$,
$\eta_n \ne \pi_n$. As similar to regular importance sampling, the optimal
forward kernel (also called proposal) is that $K_n(x_{n-1},x_n) =
\pi_n(x_n)$. This choice is clearly impossible (or otherwise the \smc method
is entirely unneeded). A few classes of kernels was used in the literature.

\paragraph{Independent proposals} It is possible to construct
$K_n(x_{n-1},x_n) = K_n(x_n)$ where $K_n$ is a density function. The
parameters can be determined by using information from $\{X_{n-1}^{(i)}\}$
\parencite[e.g.][]{West1993}. Independent proposals appear to be dependent
on good behavior of the sequence $\{\pi_n\}$. It is difficult to construct
independent proposals which approximate $\pi_n$ well in many cases. For
example, with a multi modes $\pi_n$, a standard distribution like Normal
can hardly be efficient. Therefore, it is sensible to construct local moves.

\paragraph{Local random-walk moves} An alternative to above is using
$K_n(x_{n-1},x_n)$ a random-walk kernel \parencite[e.g.][]{Givens1996}.  It
worth noting that the local random-walk here is very different from the
Metropolis random-walk. In the \mcmc case, The entire sequence of
random-walks explores a single target distribution and past moves provide
information about this distribution. In contrast, in the \smc case, at each
iteration, the target is a new distribution $\pi_n$ and information about
this distribution is not used in typical situations.  In addition, the
construct of the random-walk is difficult in the sense that standard rules
to determine the kernel bandwidths may not apply here.

\paragraph{Markov chain Monte Carlo moves} As proposed in
\textcite{DelMoral2006}, it is natural to set $K_n$ as an \mcmc kernel of
invariant distribution $\pi_n$. It is sensible in the cases either $K_n$
mixes fast enough or $\pi_n$ evolves slowly so that we can expect $\eta_n$
to be close to $\pi_n$.

Yet another type of moves is \emph{approximate Gibbs moves}, which we will
not discuss here. In the example provided later, the \mcmc move is used.

\subsection{Choice of backward kernels}
\label{sub:Choice of backward kernels}

It should be noted that the choice of backward kernel should be optimized
with respect to the chosen forward kernel. Recall that we introduced this
backward kernel to enable the evaluation of weights by doing importance
sampling on space $\prod_{i=1}^n E_i$ (or $E^n$ for the case of common
support $E$) instead of $E_n$. Intuitively the variance of the importance
weights is increased. So the optimal backward kernel will reduce this ``side
effect''. Indeed, as shown in \textcite{DelMoral2006}, the optimal backward
kernel is
\begin{equation}
  L_{n-1}^{\mathrm{opt}}(x_n,x_{n-1})
  = \frac{\eta_{n-1}(x_{n-1})K_n(x_{n-1},x_n)}{\eta_n(x_n)}
\end{equation}
and the important weights weights are
\begin{equation}
  w_n(x_{1:n}) = \frac{\gamma_n(x_n)}{\eta_n(x_n)}
\end{equation}
which is exactly the importance sampling weights in marginal space. However,
as for the same reason we need this backward kernel, the above optimal
kernels cannot be computed point-wise, since itself relies on the marginal
distribution $\eta_n$. Several sub-optimal kernels were shown in
\textcite{DelMoral2006}. The one of most interest to this report is as
below.

It was shown that with the \mcmc kernel and $\pi_n$ be close enough to
$\pi_{n-1}$, a good approximation to optimal backward kernel is given by
\begin{equation}
  L_{n-1}(x_n,x_{n-1})
  = \frac{\pi_n(x_{n-1})K_n(x_{n-1},x_n)}{\pi_n(x_n)}.
\end{equation}
In this case,
\begin{equation}
  \tilde{w}_n(x_{n-1},x_n)
  = \frac{\gamma_n(x_{n-1})}{\gamma_{n-1}(x_{n-1})},
\end{equation}
which is particularly easy to compute in many cases.

\subsection{Estimating ratio of normalizing constants}
\label{sub:Estimating ratio of normalizing constants}

The last remark about the \smc algorithm is using the computed weights to
estimate the ratio of normalizing constants, which is of interest to the
Bayesian model comparison problem. The basic identity is
\begin{equation}
  \frac{Z_n}{Z_{n-1}} =
  \frac{\int\gamma_n(x_n)\dd x_n}{\int\gamma_{n-1}(x_{n-1})\dd x_{n-1}}
\end{equation}
and the importance sampling estimates,
\begin{equation}
  \frac{\hat{Z}_n}{Z_{n-1}} =
  \sum_{i=1}^NW_{n-1}^{(i)}\tilde{w}_n(X_{n-1}^{(i)},X_n^{(i)}).
  \label{eq:z_smc}
\end{equation}
To estimate $Z_n/Z_1$, the product of the above estimates can be used. The
formula can be further simplified in the case where resampling is not
performed at each iteration \parencite{DelMoral2006}.

\section{Path sampling estimator}
\label{sec:Path sampling estimator}

The path sampling estimator for the logarithm ration of normalizing
constants is based on a simple identity. Give a sequence of distributions
say, $\gamma_t(\theta)$ known up to a normalizing constants, say $Z_t$,
where $t$ is a continuous index taken value at $[0,1]$. The path sampling
estimate of the log of ratio of normalizing constants is based on the simple
identity
\begin{align}
  Z_t &= \int\gamma_t(\theta) \\
  \frac{\diff}{\diff t}\log(Z_t)
  &= \frac{1}{Z_t}\frac{\diff}{\diff t}Z_t \\
  &= \int\frac{1}{Z_t}\frac{\diff}{\diff t}\gamma_t(\theta)\dd\theta \\
  &= \Exp_t\Square[Big]{\frac{\diff}{\diff t}\log\gamma_t(\theta)}
\end{align}
where the expectation is taken with respect to $\theta$ with $t$ fixed.
Thus, the path sampling estimator of $\log(Z_1/Z_0)$ can be written as,
\begin{equation}
  \int_0^1 \Exp_t\Square[Big]{\frac{\diff}{\diff t}\log \gamma_t(\theta)}.
  \label{eq:z_path}
\end{equation}
Note that the index $t$ does not necessarily take values on $[0,1]$, though
for simplicity we use this range and give $t$ a uniform distribution.

One way to implement the estimator above is sampling from the joint space of
$(t, \theta)$ and interpret the above integration as the expectation of the
joint random variables. An alternative way is to use a sequence $0 \le t_1 <
\dots < t_m \le 1$, and numerical integrations with trapezoidal rule.  In
other words, a sequence of distributions $\gamma_{t_n}$ are constructed.
They can be approximated using the \smc sampler as described in
Section~\ref{sec:smc algorithm}. This later method is the main theme of this
report.

\section{Example}
\label{sec:Example}

Consider two models, with likelihoods as Normal and Laplace (i.e. double
exponential) distribution respectively. Explicitly, model 1, denote by
$\calM_1$, has a likelihood
$\calN(\mu_1,\lambda_1^{-1})$, i.e.,
\begin{equation}
  f(x|\mu_1,\lambda_1) = \sqrt{\frac{\lambda_1}{2\pi}}
  \exp\Curly[Big]{-\frac{\lambda_1(x-\mu_1)^2}{2}}.
\end{equation}
Model 2, denoted by $\calM_2$, has a likelihood of a Laplace distribution,
denoted in this report by $\calL(\mu_2,\lambda_2^{-1})$, i.e.,
\begin{equation}
  f(x|\mu_2,\lambda_2) = \frac{\lambda_2}{2}
  \exp\Curly{-\lambda_2\Abs{x - \mu_2}}
\end{equation}
The Laplace distribution is parameterized in terms of a ``rate'' parameter,
similar to the case of Exponential distribution.

The true data generating mechanism is a mixture of the two distributions.
Explicitly, the true model is written as,
\begin{equation}
  X_i \sim p\calN(0,1) + (1-p)\calL(0, \sqrt{2}/2),
  \label{eq:data_density}
\end{equation}
where $p\in[0,1]$. By construction, the two components have the same
variance. In this report, we will first consider two simple case, $p = 0$ or
$1$, namely the data comes from either a Normal distribution or a Laplace
distribution. Then a set of data come from a mixture of the two, with $p =
0.5$ is considered.

\subsection{The Normal model}

A conjugate prior is specified for $\calM_1$, the Normal likelihood model.
That is, assuming the data observed are $\x = (x_1,\dots,x_n)^T$,
\begin{align}
  x_i | \mu,\lambda &\sim \calN(x_i; \mu, \lambda^{-1}) \\
  \mu | \mu_0,\lambda,n_0 &\sim \calN(\mu; \mu_0, (n_0\lambda)^{-1}) \\
  \lambda | \alpha,\beta &\sim \calGa(\lambda; \alpha, \beta)
\end{align}
In other words, the prior is a Normal-Gamma distribution with parameters
$(\mu_0, n_0, \alpha, \beta)$. Explicitly, we write the posterior density
as,
\begin{equation}
  \pi(\mu,\lambda|\x) \propto
  L(\mu,\lambda;\x)\pi(\mu,\lambda),
  \label{eq:normal_posterior}
\end{equation}
where
\begin{align}
  L(\mu,\lambda;\x) &= \Round[Big]{\frac{\lambda}{2\pi}}^{n/2}
  \exp\Curly[Big]{-\frac{\lambda}{2}\sum_{i=1}^n(x_i - \mu)^2}
  \label{eq:likelihood_normal}\\
  \pi(\mu,\lambda) &= \sqrt{\frac{n_0\lambda}{2\pi}}
  \exp\Curly[Big]{-\frac{n_0\lambda}{2}(\mu - \mu_0)^2}
  \frac{\beta^{\alpha}}{\Gamma(\alpha)}
  \lambda^{\alpha - 1}\exp\Curly{-\beta\lambda}
  \label{eq:prior_normal}
\end{align}

\subsubsection{Algorithm setting}
\label{ssub:normal_alg}

Set $\pi_0(\mu,\lambda) = \pi(\mu,\lambda)$, where $\pi(\mu,\lambda)$ is as
in Equation~\ref{eq:prior_normal}. Let
\begin{equation}
  \pi_k(\mu,\lambda) \propto (L(\mu,\lambda;\x))^{p_k}\pi_0(\mu,\lambda)
  \label{eq:normal_targets}
\end{equation}
where $L$ is the likelihood function, as in
Equation~\eqref{eq:likelihood_normal}, and $\{p_k\in[0,1]\}$ is sequence
chosen. The \smc sampler starts with $\pi_0$ and the initial importance
distribution is set to be $\pi_0$ as well.

The forward kernel, at step with target $\pi_k$ is constructed as the
following,
\begin{enumerate}
  \item Updating $\lambda$ through multiplicative Log-Normal random-walk
    proposal.
  \item Updating $\mu$ through additive Normal random-walk proposal.
\end{enumerate}
More specifically, let $\calLN(m,s^2)$ denote the Log-Normal distribution
with parameters $m$ and $s^2$. At time $k$, corresponding to step $k$, and
target $\pi_k(\mu,\lambda)$,
\begin{enumerate}
  \item Given $\lambda_k$, draw $v$ from $\calLN(0,\sigma_{\lambda}^2)$ and
    propose $\lambda_{k+1}=v\lambda_k$.
  \item Given $\mu_k$, draw $u$ from $\calN(0,\sigma_{\mu}^2)$, and propose
    $\mu_{k+1}=\mu_k+u$.
  \item Compute the acceptance probability by
    \begin{equation}
      \delta = \frac{\gamma_{k+1}(\mu_{k+1},\lambda_{k+1})}
      {\gamma_{k+1}(\mu_k,\lambda_k)}v,
      \label{eq:accept_prob}
    \end{equation}
    where $\gamma_k = \pi_k / Z_k$. Accept proposal $(\mu_{k+1},
    \lambda_{k+1})$ with probability $\delta$ as the new particle or
    otherwise copy $(\mu_k, \lambda_k)$ as the value of the new particle.
\end{enumerate}

\begin{remark}
  This is a standard Metropolis random-walk. The acceptance probability is
  derived as following. As in standard rand-walk \mcmc,
  \begin{equation}
    \delta =
    \frac{\gamma_{k+1}(\mu_{k+1},\lambda_{k+1})}
    {\gamma_{k+1}(\mu_k,\lambda_k)}
    \frac{q(\mu_k,\lambda_k|\mu_{k+1},\lambda_{k+1})}
    {q(\mu_{k+1},\lambda_{k+1}|\mu_k,\lambda_k)}
  \end{equation}
  where $q$ is the proposal density. In this case,
  \begin{align}
    q(\mu_{k+1},\lambda_{k+1}|\mu_k,\lambda_k) &=
    \calN(\mu_{k+1};\mu_k,\sigma_{\mu}^2)
    \calLN(\lambda_{k+1};\log\lambda_{k}, \sigma_{\lambda}^2)
    \allowdisplaybreaks\\
    &= \frac{1}{\sqrt{2\pi}\sigma_{\mu}}
    \exp\Curly[Big]{-\frac{1}{2\sigma_{\mu}^2}(\mu_{k+1} - \mu_k)^2}
    \notag\\ &\quad\times
    \frac{1}{\sqrt{2\pi}\sigma_{\lambda}\lambda_{k+1}}
    \exp\Curly[Big]
    {-\frac{1}{2\sigma_{\lambda}^2}(\log\lambda_{k+1}-\log\lambda_k)^2}
  \end{align}
  From here it is easy to see that
  \begin{equation}
    \frac{q(\mu_k,\lambda_k|\mu_{k+1},\lambda_{k+1})}
    {q(\mu_{k+1},\lambda_{k+1}|\mu_k,\lambda_k)} =
    \frac{\lambda_{k+1}}{\lambda_k} = v
  \end{equation}
  and hence Equation~\eqref{eq:accept_prob}.
\end{remark}

\begin{remark}
  In particular, for the numerical results which will be seen later, the
  parameters are set as follows:
  \begin{align*}
    \alpha       &= 0.1 & \beta          &= 0.1 \\
    \mu_0        &= 0 & n_0              &= 0.1 \\
    \sigma_{\mu} &= 1 & \sigma_{\lambda} &= 1
  \end{align*}
\end{remark}

\subsection{The Laplace model}

Similar to the Normal case, a prior is specified for $\calM_2$, the Laplace
likelihood model. Assuming the data observed are $\x = (x_1,\dots,x_n)^T$,
\begin{align}
  x_i | \mu,\lambda &\sim \calL(x_i;\mu,\lambda^{-1}) \\
  \mu | \mu_0,\lambda,n_0 &\sim \calL(\mu;\mu_0, (n_0\lambda)^{-1}) \\
  \lambda | \alpha,\beta &\sim \calGa(\lambda; \alpha, \beta)
\end{align}
We similarly write 
\begin{equation}
  \pi(\mu,\lambda|\x) \propto
  L(\mu,\lambda;\x)\pi(\mu,\lambda),
  \label{eq:laplace_posterior}
\end{equation}
where
\begin{align}
  L(\mu,\lambda;\x) &= \Round[Big]{\frac{\lambda}{2}}^n
  \exp\Curly[Big]{-\lambda\sum_{i=1}^n\Abs{x_i - \mu}}
  \label{eq:likelihood_laplace}\\
  \pi(\mu,\lambda) &= \frac{n_0\lambda}{2}
  \exp\Curly{-n_0\lambda\Abs{\mu - \mu_0}}
  \frac{\beta^{\alpha}}{\Gamma(\alpha)}
  \lambda^{\alpha - 1}\exp\Curly{-\beta\lambda}
  \label{eq:prior_laplace}
\end{align}

\subsubsection{Algorithm setting}
\label{ssub:laplace_alg}

Set $\pi_0(\mu,\lambda) = \pi(\mu,\lambda)$, where $\pi(\mu,\lambda)$ is as
in Equation~\ref{eq:prior_laplace}. Let
\begin{equation}
  \pi_k(\mu,\lambda) \propto (L(\mu,\lambda;\x))^{p_k}\pi_0(\mu,\lambda)
  \label{eq:laplace_targets}
\end{equation}
where $L$ is the kernel likelihood, as in
Equation~\eqref{eq:likelihood_laplace}, and $\{p_k\in[0,1]\}$ is a sequence
chosen. The \smc sampler starts with $\pi_0$ and the initial importance
distribution is set to be $\pi_0$ as well. The setting is similar to the
normal case, except for the forward kernel:
\begin{enumerate}
  \item Updating $\lambda$ with a multiplicative Log-Normal random-walk
    proposal.
  \item Updating $\mu$ with a additive Laplace random-walk proposal.
\end{enumerate}

\begin{remark}
  For the numerical results, same parameters are used as in the Normal
  model.
\end{remark}
