\ifx\inthesis\undefined % In Thesis
\input{../header}
\title{Model Comparison}
\begin{document}
\maketitle
\else % In Thesis
\chapter{Model Comparison}
\label{cha:Model Comparison}
\fi % In Thesis

Model comparison for the purposes of selection, averaging and validation is a
problem found through out statistics and related disciplines. There are two
purposes of model comparison often found in the application of statistical
theories. One is to discover the ``true'' data generating mechanism, which
actually produce the data. This aspect is often strongly related to hypothesis
testing, in the sense that it can be viewed as testing different scientific
theories about the data against each other. The other purpose it to choose the
model describes the data best or provide the best estimates of quantities of
interest. The chosen model can also be used for predictive purposes in
addition to inference purposes. It is difficult to give the phrase ``the best
model'' a precise definition. Sometimes, the true model, even it exists at all
which is much up to debate, can be to complicated for practice use. Many model
comparison strategies aim to find a balance between model complexity can
accuracy.

There are a number of approaches of model comparison has been developed. Each
has its strength and drawbacks. There is no universally best model comparison
strategy. As \cite[][chap.~4]{Myers:1990wt} pointed out, different model
comparison strategies have different purposes. Though he made the statement in
the context of regression analysis, it is much true in more general
situations.

\section{Bayesian model choice}
\label{sec:Bayesian model choice}

Bayes' theorem, in its simplest form is stated as below,
\begin{equation}
  p(H|\data) = \frac{p(\data|H)p(H)}{p(\data)} \label{eq:bayes}
\end{equation}
\sidenote{In the discussions of the views of probabilities. I believe I read
  them somewhere. However I am still finding some references to support it or
  to verify that I did not get anything wrong here.}
where $\data$ is the data and $H$ is a hypothesis. Like many other probability
theories, technically Bayes' theorem merely provides a method of accounting
for the uncertainty. There are different interpretations, rooted in the views
of probabilities. Two popular views. One is the \emph{frequentist} (or
\emph{statistical}) view among other so called \emph{objective} views. The
other is \emph{subjective} view. The frequentist view an \emph{event} as a
class of \emph{individual events} which are not only equally probable and
\emph{stochastically independent}. With a subjective view, the only thing
that matters is uncertainty and how to make informed and rational discussions
under uncertainty. Some, mostly from an objective perspective, has argued that
Bayesian modeling merely provides a convenient formulation in some situations.
From a subjective perspective, Bayesian statistics provides a rational way to
update one's \emph{personal belief} and to make rational decisions. There has
been debate over views of probability as long as statistics has been a
discipline. These topics, though will not be focused on in this thesis, are
important in both theory and practice. For example, it can affects the choice
of priors.

\sidenote{Original I saw in Bernardo cited Finetti, which I never read. So I
  previously cited sections in Bernardo which I did read. I am not quite sure
  I cited the right work of Finetti here. The one I cited are the two volume
  \emph{Theory of Probability}}
A throughout treatment of Bayesian modeling from a decision theory perspective
can be found in \cite{Robert:2007tc}. Formal mathematical representations can
also be found in \cite[][sec.~5.1 and sec.~6.1]{Bernardo:1994vd}. Notion of
rational decisions in the context of uncertainty was also made precise in the
form of axioms in \cite{DeFinetti:1974tg,DeFinetti:1975ua}. It is assumed that
a rational decision cannot be considered separately from rational beliefs. And
rational beliefs shall be built upon available information (the data in the
statistical term) and any personal preference input (the prior information in
Bayesian literatures).

\subsection{Mathematical foundations}
\label{sub:Mathematical foundations}

Consider a (possibly infinite) countable set of parametric models $\calM =
\{\calM_k\}_{k\in\calK}$. Under each model, the data is generated according to
a likelihood function $f(\data|\theta_k,\calM_k)$ where $\theta_k$ is the
parameter vector in the space $\Theta_k\subset\Real^{d_k}$, and $d_k$ is the
dimension. Within the Bayesian framework, a prior distribution is chosen for
these parameters conditional on the model, say $\pi(\theta_k|\calM_k)$. And
each model itself has a prior distribution $\pi(\calM_k)$. Therefore according
to Bayes' theorem, the posterior distribution of the parameters and the model,
conditional upon the data is given by the following density, defined on the
space $\bigcup_{k\in\calK}\{\calM_k\}\times\Theta_k$,
\begin{equation}
  \pi(\theta_k,\calM_k|\data) =
  \frac{f(\data|\theta_k,\calM_k)\pi(\theta_k|\calM_k)\pi(\calM_k)}{p(\data)}
  \label{eq:full posterior}
\end{equation}
where
\begin{align}
  p(\data) &= \sum_{k\in\calK}p(\data|\calM_k)\pi(\calM_k) \\
  p(\data|\calM_k) &=
  \int f(\data,\theta_k|\calM_k)\pi(\theta_k|\calM_k)\intd\theta_k
  \label{eq:marginal likelihood}
\end{align}
This is
sometimes also termed the \emph{full posterior}. The within model posterior
distribution of the parameter is,
\begin{equation}
  \pi(\theta_k|\data,\calM_k) =
  \frac{f(\data|\theta_k,\calM_k)\pi(\theta_k|\calM_k)}{p(\data|\calM_k)}
  \label{eq:within posterior}
\end{equation}
The term $p(\data|\calM_k)$ is termed the \emph{marginal likelihood} or the
\emph{evidence} of the model.

From equation~\eqref{eq:full posterior}, it is clear that the model posterior
probability $\pi(\calM_k|\data)$ is a marginal of the full posterior,
\begin{equation}
  \pi(\calM_k|\data) =
  \frac{
    \pi(\calM_k)
    \int f(\data|\theta_k,\calM_k)\pi(\theta_k|\calM_k)\intd\theta_k
  }{
    \sum_{l\in\calK}\pi(\calM_l)
    \int f(\data|\theta_l,\calM_l)\pi(\theta_l|\calM_l)\intd\theta_l
  }.
  \label{eq:post model prob}
\end{equation}
Bayesian model choice problem mostly centers around the inference of this
posterior model probability. Many methods for computing this probability is
reviewed in chapter~\ref{cha:Monte Carlo Methods}. In the remaining of this
section, we assume that the calculation of required quantities will be
available.

Our aim is to choose the ``best'' model from the set $\calM$. There will
usually be actions taken after the model is chosen, for example inference of
the past or prediction of the future. It is the consequences of these actions
of interest instead of the chosen model itself. Therefore, from a
decision-theoretic perspective, the ``best'' model should maximize the utility
for some quality of interest. However, in practice it is common to ignore the
actions following the model selection and the sole interest is the true model,
say $\calM_t$. In this case, it is natural to define a zero-one utility
function, say $u(\calM_k,\calM_t)$,
\begin{equation}
  u(\calM_k,\calM_t) =
  \begin{cases}
    0, &\text{if } \calM_k = \calM_t,\\
    1  &\text{otherwise.}
  \end{cases}
\end{equation}
It is easy to see that the model $\calM_k$ that maximizes the expected utility
given data $\data$ is the model with the highest posterior probability
$\pi(\calM_k|\data)$, see \cite[][chap.~6]{Bernardo:1994vd}. Also see
\cite[][sec.~7.2.1]{Robert:2007tc} for an in depth discussion of the
difficulties of the Bayesian formulation in the model choice problem and the
reason of why such a maximum posterior probability approach is adapted. It
should be noted the above argument is only valid if the true model $\calM_t
\in \calM$. Otherwise, the utility is always zero for all models. In what
follows, we presume that our aim is to find the model with the highest
posterior probability.

It should be noted that the prior distribution $\pi(\theta_k|\calM_k)$ is
chosen by statisticians in the modeling process. In chapter~\ref{cha:Bayesian
  Model Comparison for Positron Emission Tomography Compartmental Model} we
will see an example of construction of well-informed priors for a realistic
application. The choice of the prior distribution is one of the most critical
and criticized part of Bayesian modeling. In principle, the prior distribution
shall represent the prior beliefs. That is, it represents how much is already
known about the data generating mechanism and what is believed about it before
the observation of the data, no more or no less. It shall not only describe
all knowledge already known, but also more importantly preserve all the
ignorance. If it contains more information than what is actually known, the
inference will be biased. In other words, one can always construct a prior
distribution such that inference will be biased towards one's preference,
which is not necessarily rational. The priors need to be considered carefully
on a per problem basis. Nonetheless there are a few classes of prior
distributions frequently used in the Bayesian modeling. It is often too
difficult to elicit a precise distribution from prior information. Therefore
it is necessary to make at least partially arbitrary choice of the prior
distribution \cite[][chap.~3]{Robert:2007tc}\cite{Kass:1995vb}.

One of the more important class of prior distribution is conjugate priors. A
conjugate prior, say $\pi(\theta_k|\calM_k)$, for a parametric model with
likelihood $f(\data|\theta_k,\calM_k)$, is one such that the posterior
$\pi(\theta_k|\data,\calM_K)$ belongs to the same family of distributions as
the prior. In \cite[][chap.~5]{Bernardo:1994vd} it was argued that the
conjugate prior reduced the input of prior information to only the choice of
parameter values and thus cannot be fully justified from a subjective
perspective. Though their mathematical simplicity make them attractive in
practice, for many applications of interest it is near impossible to find such
priors.

In situations where no or little prior information are available, the
so-called ``non-informative'' priors are often used. One choice is the
Jeffrey's priors \cite{Jeffreys:1946jf}, which has the form
\begin{equation}
  \pi(\theta_k|\calM_k)\propto\sqrt{I(\theta_k)}
\end{equation}
where
\begin{equation}
  I(\theta_k) = \int f(\data|\theta_k,\calM_k)\Round[Big]{
    -\frac{\partial^2}{\partial\theta_k^2}\log f(\data|\theta_k,\calM_k)}
  \intd\data,
\end{equation}
\sidenote{I recall that in the early stages I encountered a few improper
  Jeffery's priors in practice and read something along the lines here.
  However, still seeking reference to support the statements here}
is the \emph{Fisher's information}. The basic idea behind Jeffrey's priors is
that the prior shall contain no more information than the observed data do.
Though intuitive, Jeffrey's priors derived for many models may be problemtic.
It is often the case that the derived Jeffrey's prior can be improper, which
makes the Bayesian model choice problem difficult to formulalize as there is
no unique scale for improper priors.

Another class non-informative priors is called \emph{reference priors}
introduced in \cite{Bernardo:1979uq}. Reference priors aims to derive priors
such that the distance between the posteriror and prior is maximized, usually
measured in terms of \kl \cite{Kullback:1951va}. In some sense, a reference
prior is the least informative prior. See \cite{Berger:1989vj, Berger:1992kf,
  Berger:1992wo} and \cite[][sec.~5.4]{Bernardo:1994vd} for more information
on this class of priors.

\subsection{Bayes factor}
\label{sub:Bayes factor}

When the model set $\calM$ is finite, we can find the model with the highest
posterior probability by compare models pairwise. To compare the posterior
probabilities of two models, say $\calM_{k_1}$ and $\calM_{k_2}$, one only
need to compute their ratio. Recall the expression~\eqref{eq:post model prob},
the ratio can be written as,
\begin{equation}
  \frac{\pi(\calM_{k_1}|\data)}{\pi(\calM_{k_2}|\data)}
  = \frac{\pi(\calM_{k_1})}{\pi(\calM_{k_2})} \frac
  {\int f(\data|\theta_{k_1},\calM_{k_1})\pi(\theta_{k_1}|\calM_{k_1})
      \intd\theta_k}
  {\int f(\data|\theta_{k_2},\calM_{k_2})\pi(\theta_{k_2}|\calM_{k_2})
      \intd\theta_k}
  = \frac{\pi(\calM_{k_1})}{\pi(\calM_{k_2})}B_{12},
  \label{eq:posterior odd}
\end{equation}
where
\begin{equation}
  B_{12} = \frac
  {\int f(\data|\theta_{k_1},\calM_{k_1})\pi(\theta_{k_1}|\calM_{k_1})
      \intd\theta_k}
  {\int f(\data|\theta_{k_2},\calM_{k_2})\pi(\theta_{k_2}|\calM_{k_2})
      \intd\theta_k}
    = \frac{p(\data|\calM_{k_1})}{p(\data|\calM_{k_2})}
  \label{eq:bayes factor}
\end{equation}
is called the Bayes factor. Equation~\eqref{eq:posterior odd} states how the
prior odds ratio is transformed into the posterior odds ratio by the Bayes
factor \cite{Kass:1995vb}. The Bayes factor is the principle tool for
Bayesian model comparison and model selection. As it is made clear in the
above equation, to compute the Bayes factor, all that needs to be done is the
computation of the marginal likelihood for each model $\calM_k\in\calM$,
\begin{equation}
  p(\data|\calM_k) =
  \int f(\data|\theta_k,\calM_k)\pi(\theta_k|k)\intd\theta_k.
\end{equation}
It is obvious that $B_{ij} = B_{ik} B_{kj}$, and thus the Bayes
factor approach is equivalent to choosing the model with the highest marginal
likelihood, as long as the model set $\calM$ is finite.

Though intuitively the influence of priors can be eliminated given enough
data. One formal assertion will be seen later in the derivation of Bayesian
information criterion (section~\ref{ssub:Bayesian information criterion}). In
the particular problem of Bayesian model comparison and selection, it shall be
noted that Bayesian model comparison is more sensitive to the choice of prior
than point or interval estimations in the sense that more data are need to
eliminate the influence of priors when it comes to the value of Bayes factor
than a posterior interval \cite{Kass:1993vy, Kass:1995vb}. \sidenote{They did
  say that, on top of pp.~782. Kass 1995. I added a half sentence to make the
  idea more clearly}

It is also important to evaluate the Bayes factor over a range of possible
priors to assess the sensitivity issues. This is often computational expensive
since many high dimensional integrations are required. When there is enough
information to construct parametric priors, it is possible to alter the values
of parameters and recompute the Bayes factor \cite{McCulloch:1991hj}. In
general situations, a less computational expensive method is to use the
Laplace approximation to compare the Bayes factor using different priors
\cite{Kass:1992tz}. It is also proposed in the literature to use the maximum
of Bayes factor (and thus the maximal evidence against a model) to evaluate
the sensitivity problem \cite{Berger:1987iq}.

The calculation of the Bayes factor can be made exact using analytical results
only occasionally. In most applications of interest, approximations has to be
used. Two approaches are widely used. On is using Monte Carlo approximations.
Another is based on the asymptotic behavior of the Bayes factor. A few of the
later is reviewed in the remaining of this section.

\subsubsection{Bayesian information criterion}
\label{ssub:Bayesian information criterion}

The Bayesian information criterion (\bic) was developed as an approximation to
the Bayes factor \cite{Schwarz:1978uv}. The \bic is defined as,
\begin{equation}
  \text{\bic} = -2\log f(\data|\hat\theta) + k\log(n).
\end{equation}
where $f(\data|\hat\theta)$ is the likelihood function evaluated at the
maximum likelihood estimator (\mle); $k$ is the number of parameters to be
estimated and $n$ is the number of observations. The \bic strategy choose the
model with the smallest \bic value. Note that in this section we dropped the
dependence on model $\calM_k$ in notations for simplicity.

To justify its use, we first outline its derivation, which will provide us
some insights of the quality of the approximation. We start with
equation~\eqref{eq:marginal likelihood} while dropping the model index $k$,
since this computations is for each model individually. Let $h(\theta) = -
\log f(\data|\theta)\pi(\theta)$ and let $\tilde\theta$ denote the value of
$\theta$ that minimizes $h(\theta)$. Then,
\begin{equation}
  p(\data) = \int f(\data|\theta)\pi(\theta)\intd\theta
  = \int\exp\{-h(\theta)\}\intd\theta
\end{equation}
Applying Taylor expansion to $h(\theta)$ around $\tilde\theta$,
\begin{align}
  h(\theta)
  &= h(\tilde\theta) + (\theta - \tilde\theta)^T h'
  + \frac{1}{2}(\theta - \tilde\theta)^T h''(\tilde\theta)
  (\theta - \tilde\theta)
  + o(\Norm{\theta - \tilde\theta})^2 \notag\\
  &\approx h(\tilde\theta) + \frac{1}{2}(\theta - \tilde\theta)^T
  H (\theta - \tilde\theta)
\end{align}
where $H = h''(\tilde\theta)$, the Hessian matrix of $h$ evaluated at
$\tilde\theta$ and $h'$ is the gradient of $h$. Since for $n\to\infty$, the
posterior distribution is concentrated around $\tilde\theta$, and thus only
those values close to $\tilde\theta$ contribute significantly to the
integration,
\begin{equation}
  p(\data)\approx\exp\{-h(\tilde\theta)\}
  \int\exp\{-\frac{1}{2}(\theta - \tilde\theta)^TH(\theta - \tilde\theta)\}.
\end{equation}
Note the integrand is the kernel of a multivariate normal distribution with
mean $\tilde\theta$ and covariance matrix $H^{-1}$, which is assumed to be
positive definite and exist. It follows,
\begin{equation}
  p(\data) \approx \exp\{-h(\tilde\theta)\} (2\pi)^{k/2} \Abs{H}^{-1/2},
\end{equation}
where $k$ is the number of parameters, or the dimension of $\theta$. Thus,
\begin{equation}
  -2\log p(\data) \approx
  -2\log f(\data|\tilde\theta) - 2\log\pi(\tilde\theta) - k\log(2\pi) +
  \log\Abs{H}.
  \label{eq:bic approx}
\end{equation}
With \iid samples, for $n\to\infty$, $H/n \approx I$, where $I$ is the Fisher
information matrix. It follows that $\Abs{H}\approx n^k \Abs{I}$ for
large $n$. Omitting the $O(1)$ terms,
\begin{equation}
  -2\log p(\data) \approx -2\log f(\data|\tilde\theta) + k\log(n).
\end{equation}
With $n\to\infty$, $\tilde\theta\approx\hat{\theta}$, where $\hat{\theta}$ is
the \mle, replace $\tilde\theta$ with $\hat{\theta}$, the right hand side of the
above equation becomes the formula for what is commonly known as \bic. The
\bic method choose the model with smallest \bic.

In addition to the large sample assumption, which is difficult to assess in
practice, \bic also assumes ``good behavior'' of the likelihood function such
that the use of \mle in place of $\tilde\theta$ is justified. As seen in its
formulation, \bic eliminates the prior for large data set.  The \bic requires
that the $O(1)$ term in equation~\eqref{eq:bic approx} is negligible compared
to other terms. These assumptions restricted the use of \bic in many
situations.  See \cite{Gelfand:1994ux} for an example where the $O(1)$
approximation failed. See \cite{Berger:2001uy} for examples that the
irregularity of likelihood function causes the \bic method failed. Moreover,
in non-\iid situations, the definition of the parameter dimension $k$ is
ambiguous \cite{Spiegelhalter:1998uc, Kass:1995vb}. There are other criticism
of the \bic strategy.  For example \cite[][sec.~7.2.3]{Robert:2007tc} argued
that the \bic strategy eliminated the subjective input into the Bayes modeling
since the value of \bic does not depend on the prior distribution. However
this is equally argued as an advantage of this strategy in the case that
priors, to which Bayes factors can be very sensitive, are hard to specify.

\subsection{Deviance information criterion}
\label{sub:Deviance information criterion}

\section{Akaike's information criterion}
\label{sec:Akaike's information criterion}

The \aic uses the \kl \cite{Kullback:1951va} as a measure of the loss when
using an approximated model in place of the true data generating mechanism. It
is built upon the relation between \kl and the maximum likelihood estimator
(\mle). The general formula of \aic for a candidate parametric model $\calM$
is
\begin{equation}
  \text{\aic} = -2\log f(\data|\hat\theta) + 2k
\end{equation}
where $\hat\theta$ is the \mle under model $\calM$ and $k$ is the number
parameters estimated. The model with the smallest \aic value is selected.  It
is first introduced by Akaike in a series of papers \cite{Akaike:1973uc,
  Akaike:1974ih, Akaike:1977ul}. It can be shown that \aic is a large sample
approximation to the expected \kl \cite{Akaike:1973uc,Bozdogan:1987wy}. From a
likelihood principle perspective, \aic acts as a balance between good fit
(high log-likelihood) and complexity in the sense that the dimension of the
parameter vector is used as a penalty term in the formula. The \aic method
aims to find models that have fewer parameters while fitting the data well.

\subsection{Comparison with \protect\bic}
\label{sub:Comparison with bic}

The \aic method is often compared with Bayesian model selection as one of the
most important frequentist model selection methods, in particular in contrast
with the \bic method. It is interesting to note that \cite{Akaike:1978ti}
has a Bayesian interpretation of the \aic procedure for the special case of a
multivariate Gaussian model. In that case, \aic can be viewed as an
approximation to the posterior probability. Without going into the details,
\cite{Akaike:1978ti} considered the situation that the sample size can be
easily increased to a large enough number while two models are very close in
the sense that the difference in their parameters are not quite visible
through the observed data. Under this setting, it was then shown that the log
of posterior model probability from a normal priors for mean vector is
approximated by $(-1/2)$\aic up to an additive constant. However we don't see
this setting as the general cases in data analysis as argued by Akaike.
Instead, in realistic cases the difficulties of model selection problem often
come from the fact that we have very limited data.

On the other hand, as seen in \cite{Akaike:1980gh}, using likelihood
function and \aic estimates as the source of objectivity of Bayesian
modeling leads to the \bic procedure. However, those with a subjective
Bayesian perspective are not likely to be convinced by the desire of
objectivity itself. In addition, as noted by \cite{Kass:1995vb}, the
Bayesian justification of \aic is only valid when the precision of the prior
distribution is comparable to that of the likelihood. This assumption is
hardly ever true in reality.

In contrast to \bic, \aic penalize the model complexity less heavily for large
sample size (the term $k\log(n)$ in \bic can easily exceeds the term $2k$ in
\aic for large $n$.) Also though developed from different origins, in some
sense \aic is more accurate (provided its underlying assumptions are
fulfilled.) The \bic approximation to Bayes factor, as we see in
section~\ref{ssub:Bayesian information criterion}, requires an $O(1)$ term to
be negligible while \aic is often at worst an $O(1/n)$ approximation
\cite{Akaike:1973uc}.

\subsection{Corrected \protect\aic}
\label{sub:Corrected aic}

We briefly review one of the most widely used extension and modification of
\aic method, the corrected \aic. This and other similar methods try to improve
the model selection procedure in the situations that
\cite{Akaike:1973uc}'s assumptions are not justified. Therefore, they
improve the robustness of the \aic procedure.

The corrected \aic, usually denoted by \aicc, mainly deals with the situation
that the sample size is not sufficient large in the sense that the dimension
of the parameter vector to be estimated is close to the sample size.
\cite{Hurvich:1989ev} developed the \aicc for regression and time series
modeling. The \aicc is defined as,
\begin{equation}
  \text{\aicc} = -2\log f(\data|\hat\theta) + \frac{2nk}{n-k-1}
\end{equation}
or equivalently,
\begin{equation}
  \text{\aicc} = \text{\aic} + \frac{2k(k+1)}{n-k-1},
\end{equation}
where $n$ is the sample size, other notations are as defined before.

It should be noted that \aicc is just one way to improve \aic for small
samples. In particular, it is derived in the case of a model with linear
structure and normal errors \cite{Hurvich:1989ev, Burnham:2002wc}. Under other
models, other form of improved \aic can be derived. \cite{Hurvich:1989ev}'s
form has also been adopted successfully in literature even in nonlinear
non-Gaussian cases, for example see \cite{Turkheimer:2003iy}.

However, to illustrate the limitation of the \aicc method, in
\cite{Zhou:2011uo} which we examined the model selection for compartment
models, the use of \aicc was shown not satisfactory for high dimension, high
noise and limited size of data. The use of \aic based methods for such models
was first introduced by \cite{Hawkins:1986ha}. However, their work, and some
recent use of \aic or \aicc mainly focus on low noise data. If the model has a
nonlinear structure and high level noise, it can hardly be approximated by
normal distribution. In such situations, as shown in \cite{Zhou:2011uo} for
\pet data, \aicc does not perform well. It is possible to derive specific \aic
based information criterion for specific models, like \cite{Hurvich:1989ev}
did for theirs. Nonetheless this will involve much more analytical work which
may or may not results in improved results.  Instead, in the our work, using
Bayesian model selection for \pet data are approached. The results are
encouraging while the implementations still has limitations.

\section{Cross validation}
\label{sec:Cross validation}

\section{Minimum description length}
\label{sec:Minimum description length}

\section{Other approaches}
\label{sec:Other approaches}

\sidenote{These other approaches may include some classical approaches, e.g.,
  those used in variable selection of regression analysis}

\ifx\inthesis\undefined
\printbibliography
\end{document}\else\relax\fi
