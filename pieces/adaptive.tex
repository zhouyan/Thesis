\documentclass[11pt, fontset = Minion]{marticle}

\def\ess{\textsc{ess}\xspace}
\def\cess{\textsc{cess}\xspace}
\def\smc{\textsc{smc}\xspace}
\def\mcmc{\textsc{mcmc}\xspace}

\def\tbw{\tilde{\mathbfit{w}}}
\def\tw{\tilde{w}}
\def\W{\mathbfit{W}}
\def\X{\mathbfit{X}}
\def\lsmc{\hat\lambda_{\text{\smc}}}
\def\lpath{\hat\lambda_{\mathrm{path}}}

\begin{document}

  \title{Adaptive schedule and conditional ESS}
  \author{Yan Zhou}
  \maketitle

  \section{Notations}

  In a \smc sampler, we denote the time index by $n$, starting with $n = 0$
  being the initialization step. The total number of moves is denoted by $T$.
  We denote the particle system at time $n$ by $\{\W_n,\X_n\}$ where $\W_n =
  \{W_n^{(i)}\}_{i=1}^N$ is the normalized weights (sum up to $1$), and $\X_n
  = \{X_n^{(i)}\}_{i=1}^N$ is the samples. We denote the incremental weights
  at time $n$ by $\tbw_n = \{\tw_n^{(i)}\}_{i=1}^N$. In the case of \mcmc move
  $\tbw_n = \tbw_n(\X_{n-1})$. Because $\tbw_n$ is a set of
  identically independently distributed draws, we will denote the random
  variable corresponding to its underlying distribution (which we usually
  don't know in closed form) simply by $\tw_n$.

  We denote the target distribution at time $n$ by $\pi_n(x) =
  \gamma_n(x)/Z_n$, where $\gamma_n(x) = \gamma(x|\alpha=\alpha_n)$ and
  $\alpha$ is the schedule parameter, i.e., the exponent in the geometry path.
  And we denote estimator for the logarithm of normalizing constants ratio,
  $\log(Z_T/Z_0)$ using standard \smc and path sampling by $\lsmc$ and
  $\lpath$, respectively. That is,
  \begin{align}
    \lsmc &= \log\Round[Big]{
      \prod_{n=1}^T \sum_{i=1}^N W_{n-1}^{(i)} \tw_n^{(i)}} \label{eq:lsmc} \\
    \lpath &= \sum_{n=1}^T\Delta\alpha_n\sum_{i=1}^NW_{n-1}^{(i)}
    \frac{\diff}{\diff\alpha}
    \log\gamma(X_{n-1}^{(i)}|\alpha)\Bigm|_{\alpha=\alpha_{n-1}}.
    \label{eq:lpath}
  \end{align}
  Of course, one can use more sophisticated numerical integration for path
  sampling and thus different expression of equation~\eqref{eq:lpath}.

  \section{Conditional ESS}

  The conditional \ess given samples up to time $n$ is written as,
  \begin{equation}
    \text{\cess}_n = N\frac{\Round[Big]{
        \sum_{i=1}^N W_n^{(i)}\tw_{n+1}^{(i)}}^2}{
      \sum_{i=1}^N W_n^{(i)}(\tw_{n+1}^{(i)})^2}
  \end{equation}
  When $N\to\infty$, \cess can be seen as an approximation of
  \begin{equation}
    \text{\cess}_n \approx N\frac{(\Exp[\tw_{n+1}])^2}{\Exp[\tw_{n+1}^2]}
  \end{equation}

  \section{Relation between estimator variance and conditional ESS}

  We will first focus on equation~\eqref{eq:lsmc}. Rewrite the equation as
  \begin{equation}
    \lsmc = \sum_{n=1}^T\hat\lambda_n(\W_{n-1},\X_{n-1})
  \end{equation}
  where
  \begin{equation}
    \hat\lambda_n(\W_{n-1},\X_{n-1}) = \log\Round[Big]{
      \sum_{i=1}^NW_{n-1}^{(i)}\tw_{n}^{(i)}}.
  \end{equation}
  Use the law of total variance,
  \begin{align}
    \var[\lsmc]
    &= \var\Square[Big]{\sum_{n=1}^T\hat\lambda_n(\W_{n-1},\X_{n-1})} \notag\\
    &=
    \Exp\Square[Big]{\var\Square[Big]{
        \sum_{n=1}^T\hat\lambda_n(\W_{n-1},\X_{n-1})\Bigm|
        \W_{0:T-2},\X_{0:T-2}}}
    \notag\\&\quad+
    \var\Square[Big]{\Exp\Square[Big]{
        \sum_{n=1}^T\hat\lambda_n(\W_{n-1},\X_{n-1})\Bigm|
        \W_{0:T-2},\X_{0:T-2}}} \notag\\
    &= \Exp[\var[\hat\lambda_T(\W_{T-1},\X_{T-1})|\W_{0:T-2},\X_{0:T-2}]]
    \notag\\&\quad+
    \var\Square[Big]{
      \sum_{n=1}^{T-1}\hat\lambda_n(\W_{n-1},\X_{n-1}) +
      \Exp[\hat\lambda_T(\W_{T-1},\X_{T-1})|\W_{0:T-2},\X_{0:T-2}]}
  \end{align}
  Recall that the particle system $\{\W_n,\X_n\}$ provides an unbiased
  estimator of $h(X_n)$ for $X_n\sim\pi_n(\cdot)$, therefore the conditional
  expectation is not really an function of the previous particle system as in
  general. However, here $\hat\lambda_n$ is actually a function of an
  importance sampling estimator. Using some low order approximation, we still
  have the following recursion relation,
  \begin{equation}
    \var[\lsmc] \approx
    \Exp[\var[\hat\lambda_T(\W_{T-1},\X_{T-1})|\W_{0:T-2},\X_{0:T-2}]] +
    \var\Square[Big]{\sum_{n=1}^{T-1}\hat\lambda_n(\W_{n-1},\X_{n-1})}.
  \end{equation}
  Note that in the case of path sampling, the corresponding $\hat\lambda_n$ is
  itself an importance sampling estimator, therefore the above approximation
  become exact. This relation leads to,
  \begin{equation}
    \var[\lsmc] \approx \var[\hat\lambda_1(\W_0,\X_0)] +
    \sum_{n=2}^T
    \Exp[\var[\hat\lambda_n(\W_{n-1},\X_{n-1})|\W_{0:n-2},\X_{0:n-2}]]
  \end{equation}
  Note that this equation does not require any assumption about the resampling
  schedule, the type of between iteration moves, etc. So the unbiasedness
  property of the \smc sampler lead to a simple decomposition of the variance
  of the logarithm of normalizing constants ratio. Now exam the
  expectation of the conditional variance, now apply the delta method in the
  limit case $N\to\infty$,
  \begin{align}
    \Exp[\var[\hat\lambda_n(\W_{n-1},\X_{n-1})|\W_{0:n-2},\X_{0:n-2}]]
    &= \Exp\Square[Big]{\var\Square[Big]{
        \log\frac{\hat{Z}_n}{Z_{n-1}}\Bigm|\W_{0:n-2},\X_{0:n-2}}} \notag\\
    &\approx \Exp\Square[Big]{
      \frac{\var[\hat{Z}_n/Z_{n-1}\Bigm|\W_{0:n-2},\X_{0:n-2}]}
      {(\Exp[\hat{Z}_n/Z_{n-1}\Bigm|\W_{0:n-2},\X_{0:n-2}])^2}}
  \end{align}
  Note that $\hat{Z}_n/Z_{n-1} = \sum_{i=1}^N\W_{n-1}^{(i)}\tw_{n}^{(i)}$.
  Using the unbiasedness, 
  \begin{equation}
    \Exp[\hat{Z}_n/Z_{n-1}] =
    \Exp[\hat{Z}_n/Z_{n-1}|\W_{0:n-2},\X_{0:n-2}] =
    Z_n/Z_{n-1}
  \end{equation}
  It follows, 
  \begin{align}
    \Exp[\var[\hat\lambda_n(\W_{n-1},\X_{n-1})|\W_{0:n-2},\X_{0:n-2}]]
    &\approx \Exp\Square[Big]{\Round[Big]{
        \frac{\Exp[(\hat{Z}_n/Z_{n-1})^2|\W_{0:n-2},\X_{0:n-2}]}
        {(\Exp[\hat{Z}_n/Z_{n-1}|\W_{0:n-2},\X_{0:n-2}])^2} - 1}} \notag\\
    &= \Exp\Square[Big]{\Round[Big]{
        \frac{\Exp[(\hat{Z}_n/Z_{n-1})^2|\W_{0:n-2},\X_{0:n-2}]}
        {(\Exp[\hat{Z}_n/Z_{n-1}])^2} - 1}} \notag\\
    &= \frac{\Exp[(\hat{Z}_n/Z_{n-1})^2]}{(\Exp[\hat{Z}/Z_{n-1}])^2} - 1
    \label{eq:approx_lambda_n}
  \end{align}
  The two expectations can be approximated by the particle system and draws of
  incremental weights. That is, if we substitute $\hat{Z}/Z_{n-1} =
  \sum_{i=1}^NW_{n-1}^{(i)}\tw_n^{(i)}$,
  \begin{equation}
    \Exp[\var[\hat\lambda_n(\W_{n-1},\X_{n-1})|\W_{0:n-2},\X_{0:n-2}]]
    \approx \frac{N}{\text{\ess}_{n-1}}\Round[Big]{
      \frac{N}{\text{\cess}_{n-1}} - 1}
  \end{equation}
  Note that if we assume that iterations are independent of each other, than
  we directly have the approximation~\eqref{eq:approx_lambda_n}.

  \begin{remark}
    There is an implicit assumptions behind these approximations. At time $n$,
    we assumes that we are using draws $\X_n$ from some importance sampling
    distribution $\eta_n(\cdot)$ and corresponding weights $\W_n$ to
    approximate the target distribution $\gamma_n(\cdot)/Z_n$. However, in the
    case of \mcmc move, if the kernel of the \mcmc algorithm is not fast
    mixing, the actual draws $\X_n$ is not really distributed according to
    $\eta_n(\cdot)$. For example, if the \mcmc chain moves very slow or the
    accept rate is very low, then after one move, the draws is still
    approximated distributed as $\eta_{n-1}(\cdot)$.

    Therefore, an adaptive schedule based on the above observations will only
    have superior performance if we use multiple \mcmc moves between
    iterations or provide a large number of intermediate distributions.
  \end{remark}

  \begin{remark}
    One intuition here is to have the conditional variance being constant.
    That is each iteration contribute a constant amount of variance to the
    final estimator.

    In the special case of geometry path, because of the special form of
    $\frac{\diff}{\diff\alpha}\gamma(x|\alpha)$, we can relate it to the
    incremental weights. This leads to a deterministic relation between
    $\Delta\alpha_n$ and the variance of path sampling integrands. This
    relation simplifies the computation of the adaptive schedule.
  \end{remark}

  \section{A summary of empirical results}

  First, using single \mcmc move, the adaptive schedule does not out perform
  a hand crafted piecewise linear schedule.

  Second, if we increase the number of \mcmc moves between iterations, then
  with about 20 moves, the adaptive schedule out perform the piecewise linear
  schedule. The difference of Monte Carlo variance of the estimator between
  the two schedules is about 40\%. The variance itself is reduced by a factor
  of almost 100. To avoid possible numerical stability problem which is shared
  by all Monte Carlo experiment, the procedure was run for five times with
  different seed. Same results were obtained.

  Increasing the number of \mcmc moves benefit the adaptive schedule more than
  the piecewise schedule. But at certain point, increasing computational power
  in this way, brings only marginal reduction of Monte Carlo variance using
  either schedule.

  Fourth, using a \mcmc kernel that adaptive itself through very simple
  formulas which involves the parameter $\alpha$, we can obtain better accept
  rate than the piecewise kernel used in the code of the original paper. The
  reduction of variance is reduced by a factor about 4. However this along
  does not lead the adaptive schedule to out perform the piecewise linear
  schedule.

  As said, it is obvious that increasing the number of \mcmc moves will not
  improve the performance of the estimator after sufficient number of moves.
  So I tried to use larger number of distributions and a single \mcmc move. To
  get the computational time under control, only 1,000 particles was used.
  Since we are using a geometry path, the adaptive scheduler was constructed
  based on the path sampling estimator. That is, the sampler maintains a
  constant value of $\Delta\alpha_n^2\widehat{\var[\ell(\X_{n-1})]}$, where
  $\ell(\X)$ is the vector of log-likelihood given the samples $\X$. The
  computational power will be controlled through $\Delta\alpha_1$, the
  distance of the first step. It is almost a straight line with slope $-1$.
  That is, the computational power can be controlled easily through the value
  $\Delta\alpha_1$. Similar results was obtained through adaptive on
  conditional \ess.

\end{document}
