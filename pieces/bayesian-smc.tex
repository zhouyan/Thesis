% $\alpha$ provides an \emph{annealing schedule} which is intended to allow
% the control of the discrepancy between pairs of adjacent distributions. This
% gives the joint prior on model order and parameters as an initial
% distribution and gradually introduces the influence of the likelihood until
% the full posterior is reached.

% Given a weighted collection of samples $\{W^{(k,i)}_T, X^{(k,i)}_{T} =
% (K_T^{(k,i)},\theta_T^{(k,i)})\}_{i=1}^N$ targeting $\pi^{(1)}$, one may
% approximate the two distributions of interest using the empirical measures,
% \begin{align*}
%   \hat{\pi}^{(1)}(K = k) &= \sum\limits_{i=1}^N W^{(k,i)} \delta_{k,
%   K^{(k,i)}_T} \\
%   \hat{\pi}^{(1)}(d\theta|K=k) &= \frac{1}{\hat{\pi}^{(1)}(K = k)}
%   \sum\limits_{i=1}^N W^{(k,i)} \delta_{k, K_T^{(k,i)}}
%   \delta_{\theta^{(k,i)}_T}(d\theta),
% \end{align*}
% where $\delta_{k,K^{(k,i)}_T}$ denotes the \emph{Kronecker} delta and
% $\delta_{\theta{(k,i)}}$ denotes the Dirac measure concentrated at
% $\theta^{(k,i)}$.

% Thus, the output of such an \smc algorithm may be used as a (weighted)
% equivalent to that from a suitable \rjmcmc algorithm, with the posterior
% probability of each model corresponding to the (weighted) proportion of
% samples from that model.

% It is straightforward to use different numbers of samples, $N$, for each
% model when appropriate. in settings in which some models can be
% characterised substantially more easily than others.

%Note that the standard \smc unbiased estimator is in fact the
%ratio of normalizing constants between the initial distribution and the final
%distribution. In \smc[2], we initialised the system with the prior
%distribution and thus the estimates are directly the evidence for each model.

%Indeed, in settings in which the \smc importance weights
%for target distribution $\pi_{\alpha}$ depend only upon the sample at time
%$t-1$, as in the proposed algorithms, the computational cost of the new
%weights are often minimal compared to generate new samples.

% It is straightforwardly possible to use more sophisticated numerical
% integration techniques in order to evaluate the approximation of the path
% sampling estimator. Even in the presence of adaptive annealing schemes, it
% is reasonably straightforward to implement higher order schemes than the
% simple Trapezoidal approximation. In a related setting, this was shown to
% provide an appreciable reduction in bias by \cite{Friel:2012}. In our
% context we have found that the bias of even the simple Trapezoidal scheme is
% inconsequential in the regime in which the variance of this method is small
% enough to be competitive and so in the interests of parsimony we have not
% investigated such schemes.

% It is possible to use numerical integration methods other than the
% Trapezoidal rules to improve the path sampling estimator. For example, in a
% \smc[2] algorithm, if a sequence of distribution indexed by
% $\{\alpha(t/T)\}_{t=0}^T$ are used, where the path sampling integration is
% with respect to $\alpha\in[0,1]$. Then by placing an additional set of
% distributions at middle points
% $\{(\alpha(t/T)+\alpha((t+1)/T))/2\}_{t=0}^{T-1}$, Simpson's rule can be
% applied and can reduce the bias of the estimator given the same total number
% of distributions in some situations. Using similar techniques, other methods
% of numerical integration an be applied easily as well.

% There may or may not be a significant improvement through using these more
% sophisticated numerical integration methods, as other factors of the sampler
% may dominate the bias and variance of the estimates. Nonetheless, with very
% little effort, this kind of refinement is possible in principal within the
% \smc-\ps framework.

%% \ess only measures the performance of the particle system approximating the
%% target distributions, rather than the variances of the target distributions
%% themselves, which contributes to the variance of incremental weights. As seen
%% in equation~\eqref{eq:smc2-ds} and also for path sampling estimates when using
%% a geometric schedule, the variance of the incremental weights affect the
%% normalizing constants estimates directly. In the case of resampling at every
%% time step, the weights are directly normalized from the incremental weights.
%% In the general situation, as usual, let $W_{n-1}^{(i)}$ denote the
%% \emph{normalized weights} of particle $i$ at the end of time $t = n - 1$, and
%% $w_n^{(i)}$ denote the \emph{unnormalized} incremental weights of particle $i$
%% during the move at $t = n$. In the absence of resampling, we have the
%% recursive relationship,
%% \begin{equation*}
%%   W_n^{(i)} =
%%   \frac{W_{n-1}^{(i)}w_n^{(i)}}{\sum_{j=1}^NW_{n-1}^{(j)}w_n^{(j)}}
%% \end{equation*}
%% and the $\ess_n$,
%% \begin{equation}
%%   \ess_n = \frac
%%   {\bigl(\sum_{j=1}^NW_{n-1}^{(j)}w_n^{(j)}\bigr)^2}
%%   {\sum_{j=1}^N\bigl(W_{n-1}^{(j)}\bigr)^2\bigl(w_n^{(j)}\bigr)^2}
%% \end{equation}
%% If we do resampling after time $t = n - 1$ and before $t = n$, and let
%% $\bar{w}_n^{(i)}$ denote the new incremental weights after resampling, then we
%% have the new $\ess_n$, during move at $t = n$, as,
%% \begin{equation}
%%   \overline{\ess}_n = N \frac
%%   {\bigl(\sum_{j=1}^N\frac{1}{N}\bar{w}_n^{(j)}\bigr)^2}
%%   {\sum_{j=1}^N\frac{1}{N}\bigl(\bar{w}_n^{(j)}\bigr)^2}
%%   \label{eq:ess_before_res}
%% \end{equation}
%% \ess also provides information on ``smoothness'' of the sequence of
%% distributions in the sense that, it measures the discrepancy between sampling
%% distribution and the target distribution and if the target distributions
%% changes little, so shall be \ess. However, this link between \ess and the
%% ``smoothness'' is less direct. Another undesirable aspects of \ess is that its
%% evolution changes when different resampling strategies are used even when the
%% underlying target distributions are the same. Our motivation of extending the
%% concept of \ess is to adaptively place the distributions as if we do
%% resampling at every step without actually carrying out the resampling. Using
%% the unbiasedness of resampling, we can approximate $\overline{\ess}_n$ with
%% \begin{equation}
%%   \cess_n = \frac
%%   {\bigl(\sum_{j=1}^NW_{n-1}^{(j)}w_n^{(j)}\bigr)^2}
%%   {\sum_{j=1}^N\frac{1}{N}W_{n-1}^{(j)}\bigl(w_n^{(j)}\bigr)^2}
%% \end{equation}
%% where by $\cess_n$ we denote the ``conditional \ess'' as it depends upon a
%% consistent approximation of the variance of incremental weights. If we have
%% independent, identically distributed samples from the target distribution at
%% time $t = n - 1$, then $\cess_n$ tells us, essentially, how much variability
%% there would be in those incremental weights. And this variability reflects the
%% difference of the target distribution at time $t = n$ with the previous one.
%% This link is more obvious in the case where
%% equation~\eqref{eq:inc weight mcmc} is used to calculate the incremental
%% weights $w_n(x_{n-1},x_{n}$). Intuitively, \cess provides a direct measurement
%% of the ``smoothness'' of the sequence of distributions.

%% When resampling is performed at every step, then $\cess_n = \ess_n$.
%% Asymptotically, as the number of particles goes to infinity, adaptively
%% placing distributions such that $\cess_n = \cess^\star$ for a fixed value
%% $\cess^\star$ will give the same schedule as the resampling-every-time \ess
%% variant.


%% \ess only measures the performance of the particle system approximating the
%% target distributions, rather than the variances of the target distributions
%% themselves, which contributes to the variance of incremental weights. As seen
%% in equation~\eqref{eq:smc2-ds} and also for path sampling estimates when using
%% a geometric schedule, the variance of the incremental weights affect the
%% normalizing constants estimates directly. In the case of resampling at every
%% time step, the weights are directly normalized from the incremental weights.
%% In the general situation, as usual, let $W_{n-1}^{(i)}$ denote the
%% \emph{normalized weights} of particle $i$ at the end of time $t = n - 1$, and
%% $w_n^{(i)}$ denote the \emph{unnormalized} incremental weights of particle $i$
%% during the move at $t = n$. In the absence of resampling, we have the
%% recursive relationship,
%% \begin{equation*}
%%   W_n^{(i)} =
%%   \frac{W_{n-1}^{(i)}w_n^{(i)}}{\sum_{j=1}^NW_{n-1}^{(j)}w_n^{(j)}}
%% \end{equation*}
%% and the $\ess_n$,
%% \begin{equation}
%%   \ess_n = \frac
%%   {\bigl(\sum_{j=1}^NW_{n-1}^{(j)}w_n^{(j)}\bigr)^2}
%%   {\sum_{j=1}^N\bigl(W_{n-1}^{(j)}\bigr)^2\bigl(w_n^{(j)}\bigr)^2}
%% \end{equation}
%% If we do resampling after time $t = n - 1$ and before $t = n$, and let
%% $\bar{w}_n^{(i)}$ denote the new incremental weights after resampling, then we
%% have the new $\ess_n$, during move at $t = n$, as,
%% \begin{equation}
%%   \overline{\ess}_n = N \frac
%%   {\bigl(\sum_{j=1}^N\frac{1}{N}\bar{w}_n^{(j)}\bigr)^2}
%%   {\sum_{j=1}^N\frac{1}{N}\bigl(\bar{w}_n^{(j)}\bigr)^2}
%%   \label{eq:ess_before_res}
%% \end{equation}
%% \ess also provides information on ``smoothness'' of the sequence of
%% distributions in the sense that, it measures the discrepancy between sampling
%% distribution and the target distribution and if the target distributions
%% changes little, so shall be \ess. However, this link between \ess and the
%% ``smoothness'' is less direct. Another undesirable aspects of \ess is that its
%% evolution changes when different resampling strategies are used even when the
%% underlying target distributions are the same. Our motivation of extending the
%% concept of \ess is to adaptively place the distributions as if we do
%% resampling at every step without actually carrying out the resampling. Using
%% the unbiasedness of resampling, we can approximate $\overline{\ess}_n$ with
%% \begin{equation}
%%   \cess_n = \frac
%%   {\bigl(\sum_{j=1}^NW_{n-1}^{(j)}w_n^{(j)}\bigr)^2}
%%   {\sum_{j=1}^N\frac{1}{N}W_{n-1}^{(j)}\bigl(w_n^{(j)}\bigr)^2}
%% \end{equation}
%% where by $\cess_n$ we denote the ``conditional \ess'' as it depends upon a
%% consistent approximation of the variance of incremental weights. If we have
%% independent, identically distributed samples from the target distribution at
%% time $t = n - 1$, then $\cess_n$ tells us, essentially, how much variability
%% there would be in those incremental weights. And this variability reflects the
%% difference of the target distribution at time $t = n$ with the previous one.
%% This link is more obvious in the case where
%% equation~\eqref{eq:inc weight mcmc} is used to calculate the incremental
%% weights $w_n(x_{n-1},x_{n}$). Intuitively, \cess provides a direct measurement
%% of the ``smoothness'' of the sequence of distributions.

%% When resampling is performed at every step, then $\cess_n = \ess_n$.
%% Asymptotically, as the number of particles goes to infinity, adaptively
%% placing distributions such that $\cess_n = \cess^\star$ for a fixed value
%% $\cess^\star$ will give the same schedule as the resampling-every-time \ess
%% variant.

%% Before we present the proposition, we formalize some notations, which follow
%% \cite{DelMoral:2004ux}, where more detailed theoretical treatment of the
%% topic can be found. The importance sampling estimates from a \smc sampler can
%% be viewed as empirical approximation to a Feynman-Kac flow,
%% $\{\hat\eta_t\}_{t\ge0}$, on increasing spaces of
%% $\{E_t^\prime =\prod_{k=0}^tE_k\}_{t\ge0}$. At each iteration $t = n$, the sampling
%% step, which update each particles with a Markov kernel, the distribution
%% $\hat\eta_{n-1}$ is updated with Markov transition $M_n$ to $\eta_n =
%% \hat\eta_{n-1}M_n$, and the resampling step, if multinomial resampling is
%% applied, update the distribution $\eta_n$ to $\hat\eta_n = \Psi_n(\eta_n)$,
%% where
%% \begin{equation}
%%   \Psi_n(\eta_n)(\diff x_{0:n}) =
%%   \frac{G_n(x_{0:n})\eta_n(\diff x_{0:n})}{\eta_n(G_n)}
%% \end{equation}
%% and $G_n(x_{0:n})$ is called the potential function and can be viewed as a
%% generalization of the weighting function before. For example, in the generic
%% algorithm describe in the beginning of Section~\ref{sec:Methodology}, the
%% sequence of distributions on increasing dimensions $\tilde\pi_n$ is
%% interpreted as the flow $\hat\eta_n$. The Markov transition $M_n$ can be
%% defined in terms of the Markov kernel on marginal distributions $K_n(x_{n-1},
%% x_n)$.

%% \comment{Notations are still not quite clear. In the Feynman-Kac
%%   interpretation, actually the $x_n$ here is the path $x_{0:n}$ where the
%%   later $x_n$ is the particle in previous sections. Maybe I shall rewrite this
%%   part in terms of the $x_{0:n}$}{YZ}

%% With a particular \smc algorithm output, $\hat\eta_n$ is approximated by the
%% empirical measure, $\hat\eta_n(\diff x) \approx \frac{1}{N}\sum_{i=1}^N
%% \delta_{X_n^{(i)}}(\diff x)$

%% In the proposition and corollary, we also assume the following regularity
%% conditions on the pair $(G_t, M_t)$,
%% \begin{compactitem}
%%   \item $(G)$ There exists a sequence of strictly positive numbers
%%     $\epsilon_t(G)\in(0,1]$ such that for any $u_t, v_t\in E_t^\prime$,
%%     \begin{equation*}
%%       G(u_t) \ge \epsilon_t(G)G_t(v_t) > 0
%%     \end{equation*}
%%   \item $(M)_m$ There exists some integer $m\ge1$ and some sequence of numbers
%%     $\epsilon_p(M)\in(0,1)$ such that for $p$ and $u_p,v_p\in E_p'$ we have
%%     \begin{equation*}
%%       M_{p,p+m}(u_p,\cdot) = M_{p+1}M_{p+2}\dots M_{p+m}(u_p,\cdot)
%%       \ge \epsilon_p(M) M_{p,p+m}(v_p,\cdot)
%%     \end{equation*}
%% \end{compactitem}


  %% Does anyone have the energy to work out what the /correct/ explicit form is?
  %% With a little effort, the recursion can be explicitly written in the form,
  %% \begin{equation}
  %%   V_T(\xi_{0:T}) = \sum_{j=0}^T\var_{\pi_j}\biggl(
  %%   \sum_{i=j}^T\beta_i\frac{\tilde\pi_{i,j}(X_j)}{\tilde\pi_{j,j}(X_j)}
  %%   \int\tilde\pi_{i|j}(x_i|X_j)(\xi_i(x_i) - \pi_i(\xi_i))\intd x_i
  %%   \biggr)
  %% \end{equation}
  %% where $\tilde{\pi}_{i,j}$ is the $j^{\text{th}}$ coordinate marginal of
  %% $\tilde{\pi}_i$ and we adopt the conventions that $\tilde{\pi}_{j|j}
  %% = \mathsf{Id}$ .

% Recall that, the purpose of using an adaptive schedule is to construct a
% ``smooth'' sequence of distributions. Though the precise meaning of
% ``smoothness'' may vary from one application to another and both changes in
% \ess and \cess can be reasonably used as measures of it, it shall note that
% at very least, this is a property of the sequence of the distributions
% regardless of the resampling strategies. From this perspective, using is
% \cess is a more plausible approach.

% In terms of the actual performance when using the \cess adaptive strategy
% in \smc[2] algorithm, a reduction of standard deviation of 20\% was
% observed comparing to $\alpha(t/T) = t/T$ and very close to the carefully
% hand-chosen $\alpha(t/T) = (t/T)^2$. When applied to the \smc[3]
% algorithm, 50\% reduction was observed. If the \ess adaptive strategy is
% used instead, similar standard deviation reduction is observed when
% resampling is performed every iteration but no significant effect was
% observed when resampling was only performed when $\ess < N/2$.

% However, there are no significant improvement in terms of reduction of
% estimator variances. This can be viewed as evidence that \smc algorithms
% are more robust to the change of proposal scales.
